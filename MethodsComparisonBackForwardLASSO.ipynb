{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5eb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset: Study hours, previous exam scores, and pass/fail labels\n",
    "data = {'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
    "        'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}  # 0 = Fail, 1 = Pass\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df[['StudyHours', 'PrevExamScore']]\n",
    "y = df['Pass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a2ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Pass   R-squared:                       0.758\n",
      "Model:                            OLS   Adj. R-squared:                  0.688\n",
      "Method:                 Least Squares   F-statistic:                     10.94\n",
      "Date:                Thu, 15 May 2025   Prob (F-statistic):            0.00701\n",
      "Time:                        16:26:52   Log-Likelihood:               -0.17258\n",
      "No. Observations:                  10   AIC:                             6.345\n",
      "Df Residuals:                       7   BIC:                             7.253\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.3333      1.464     -0.228      0.826      -3.796       3.129\n",
      "StudyHours        0.1515      0.324      0.468      0.654      -0.615       0.918\n",
      "PrevExamScore -3.053e-16      0.054  -5.68e-15      1.000      -0.127       0.127\n",
      "==============================================================================\n",
      "Omnibus:                        0.086   Durbin-Watson:                   1.491\n",
      "Prob(Omnibus):                  0.958   Jarque-Bera (JB):                0.311\n",
      "Skew:                           0.000   Prob(JB):                        0.856\n",
      "Kurtosis:                       2.136   Cond. No.                     1.01e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.01e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Pass   R-squared:                       0.750\n",
      "Model:                            OLS   Adj. R-squared:                  0.719\n",
      "Method:                 Least Squares   F-statistic:                     24.00\n",
      "Date:                Thu, 15 May 2025   Prob (F-statistic):            0.00120\n",
      "Time:                        16:26:52   Log-Likelihood:               -0.32644\n",
      "No. Observations:                  10   AIC:                             4.653\n",
      "Df Residuals:                       8   BIC:                             5.258\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -1.0000      0.319     -3.138      0.014      -1.735      -0.265\n",
      "PrevExamScore     0.0250      0.005      4.899      0.001       0.013       0.037\n",
      "==============================================================================\n",
      "Omnibus:                        0.471   Durbin-Watson:                   1.575\n",
      "Prob(Omnibus):                  0.790   Jarque-Bera (JB):                0.372\n",
      "Skew:                          -0.375   Prob(JB):                        0.830\n",
      "Kurtosis:                       2.425   Cond. No.                         225.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i0397027\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:430: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=10 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n",
      "C:\\Users\\i0397027\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:430: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=10 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant (intercept) to the features\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the Ordinary Least Squares (OLS) regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Display the model summary (including p-values)\n",
    "print(model.summary())\n",
    "\n",
    "# Remove feature with highest p-value (if greater than 0.05)\n",
    "if model.pvalues['StudyHours'] > 0.05:\n",
    "    X = X.drop(columns='StudyHours')\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Final model after backward elimination\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475cb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Forward Selection: ['PrevExamScore']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def forward_selection(X, y):\n",
    "    remaining_features = set(X.columns)\n",
    "    selected_features = []\n",
    "    current_score = 0.0\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores_with_candidates = []\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            features_to_test = selected_features + [feature]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X[features_to_test], y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Train the model\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            score = r2_score(y_test, y_pred)\n",
    "            \n",
    "            scores_with_candidates.append((score, feature))\n",
    "        \n",
    "        # Select the feature with the highest R-squared score\n",
    "        scores_with_candidates.sort(reverse=True)\n",
    "        best_score, best_feature = scores_with_candidates[0]\n",
    "        \n",
    "        if current_score < best_score:\n",
    "            remaining_features.remove(best_feature)\n",
    "            selected_features.append(best_feature)\n",
    "            current_score = best_score\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Run forward selection\n",
    "best_features = forward_selection(X, y)\n",
    "print(f\"Selected features using Forward Selection: {best_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993db6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score: 0.9997884297520662\n",
      "LASSO Coefficients: [0.         0.02463636]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the LASSO model with a regularization parameter (alpha)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "\n",
    "# Train the LASSO model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "# Display the LASSO coefficients\n",
    "print(f'LASSO Coefficients: {lasso_model.coef_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
